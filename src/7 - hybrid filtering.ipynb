{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e5d5c28-265b-4ab9-b083-15d18ab03da1",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1 id='hybrid-filtering' style='color:#7159c1; font-size:350%'>Hybrid Filtering</h1>\n",
    "    <i style='font-size:125%'>Combining Content-Based Filtering, Collaborative Filtering and Demographic Filtering</i>\n",
    "</center>\n",
    "\n",
    "> **Topics**\n",
    "\n",
    "```\n",
    "- üç° Collaborative Filtering Problems\n",
    "- üç° Hybrid Filtering\n",
    "- üç° Hands-on\n",
    "- üç° Benchmarking\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87867ee-0309-43b9-bd9e-1037877e3cf9",
   "metadata": {},
   "source": [
    "<h1 id='0-collaborative-filtering-problems' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>üç° | Collaborative Filtering Problems</h1>\n",
    "\n",
    "Collaborative Filtering has some issues that we have to pay attention, being the `computational cost and time` the first one. As seen on Collaborative Filtering Item-Based Algorithm, a laptop with 12GB of RAM memory got 100% usage of this hardware, even though the dataset's sample being small compared to the total amount of data: only a few more datas than a million observations out of up to twenty-three million.\n",
    "\n",
    "Another problem is the `available data`. Since our dataset is large and contains observations from a bunch of users and animes, we did not face it off, but it is important to have this issue in mind. Collaborative Filtering requires a good number of users ratings of each anime in order to better recognizing the users tastes and retrieving more suitable recommendations. Due to this, when the platform has new users or new released animes, the Collaborative Filtering may not work very well with them, since the available data about them is scarce.\n",
    "\n",
    "The solution for the first problem is literally using a more powerful machine too do the tasks, changing the algorithm for more performatic ones.\n",
    "\n",
    "About the second problem, we can go into `Hybrid Filtering`, the best and last Recommendation System Technique we are going to see in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8408f1c6-3dac-4162-847b-a4c93a636aea",
   "metadata": {},
   "source": [
    "<h1 id='1-hybrid-filtering' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>üç° | Hybrid Filtering</h1>\n",
    "\n",
    "`Hybrid Filtering` combines the Content-Based Filtering and the Collaborative Filtering altogether. It normally applies the first technique when there are few users ratings available for a given anime and smoothly replaces it to the second technique as more users ratings become avaible for the given anime.\n",
    "\n",
    "Making things clearer, picture a situation where only a few users have rated Dragon Ball Z, in light of the small number of ratings, the technique will use Content-Based Filtering and recommend similar animes to Dragon Ball Z.\n",
    "\n",
    "On the other hand, a situation where many users have rated Noragami anime, due to the large number of ratings, the technique will use Collaborative Filtering and recommend similar items that similar users have liked.\n",
    "\n",
    "About the advantages:\n",
    "\n",
    "> **Content-Based Filtering and Collaborative Filtering** - `since Hybrid Filtering combines the both techniques and switches between them accordingly to the chosen user/item, this technique has the advantages of both of them`;\n",
    "\n",
    "> **Better Recommendations and Small Bubble** - `consequently, better recommendations are made with a tiny probability of creating a Bubble of Recommendations`.\n",
    "\n",
    "<br />\n",
    "\n",
    "Disadvantages-wise:\n",
    "\n",
    "> **Content-Based Filtering and Collaborativee Filtering** - `it also has the chosen technique to the chosen user/item disadvantages`;\n",
    "\n",
    "> **Required Users and Items Data** - `it requires that the dataset contains datas about the items and the users, as well as the interactions between them, that is, the users ratings for the items`;\n",
    "\n",
    "> **Computational Cost and Time** - `also, more computational cost and time is needed for the model`.\n",
    "\n",
    "<br />\n",
    "\n",
    "In this notebook, we are going to apply Hybrid Filtering merging `Collaborative Filtering based on Items' Metadatas` with `Collaborative Filtering based on Users` and `Demographic Filtering`. Thus, before heading to the code, let's see how this algorithm works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd00015-5f2a-415f-abcf-ce471f2d3b65",
   "metadata": {},
   "source": [
    "<h1 id='2-hands=on' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>üç° | Hands-on</h1>\n",
    "\n",
    "Steps:\n",
    "\n",
    "```\n",
    "- Settings;\n",
    "- Demographic Filtering Algorithm;\n",
    "- Content-Based Filtering Items' Metadatas Algorithm;\n",
    "- Collaborative Filtering Users-Based Algorithm;\n",
    "- Recommendations.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23fb8cb-346e-42c7-ae5b-e8b3d15e5d42",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**- Settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e8648cd-6a62-4e02-86f8-02c11b668a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Imports ----\n",
    "import numpy as np                                           # pip install numpy\n",
    "import pandas as pd                                          # pip install pandas\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # pip install sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# ---- Constants ----\n",
    "DATASETS_PATH = ('./datasets')\n",
    "SEED = (20240420) # April 20, 2024 (fourth Bitcoin Halving)\n",
    "\n",
    "ANIMES_SCORED_BY_CUTOFF = (0.75)\n",
    "USERS_NUMBER_RATINGS_CUTOFF = (2_000)\n",
    "BASELINE_PREDICTION = (2.5)\n",
    "\n",
    "# ---- Settings ----\n",
    "np.random.seed(SEED)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# ---- Functions: Content-Based Filtering ----\n",
    "def generate_metadatas_sequential_text(dataset, features):\n",
    "    \"\"\"\n",
    "    \\ Description:\n",
    "        - iters each dataset row and features parameter's elements;\n",
    "        - if the value at row[feature] position is different than a single hyphen:\n",
    "             - the value gets all spaces replaced by underscores;\n",
    "             - the value gets all commas-spaces replaced by space;\n",
    "             - sequential_text is incremented by the resultant value and by a space at the end;\n",
    "             - sequential_text is stripped and appended into sequential_text_list;\n",
    "             - at the end, sequential_text_list is returned.\n",
    "    \n",
    "    \\ Paramters:\n",
    "        - dataset: Pandas DataFrame;\n",
    "        - features: list of strings.\n",
    "    \"\"\"\n",
    "    sequential_text_list = []\n",
    "    \n",
    "    for index, row in dataset.iterrows():\n",
    "        current_sequential_text = ''\n",
    "        for feature in features:\n",
    "            if row[feature] != '-':\n",
    "                current_sequential_text += row[feature].replace(' ', '_').replace(',_', ' ')\n",
    "                current_sequential_text += ' '\n",
    "                     \n",
    "        sequential_text_list.append(current_sequential_text.strip())\n",
    "    \n",
    "    return sequential_text_list\n",
    "\n",
    "def get_recommendations_content_filtering(df, title, animes_indices, cosine_similarity, number_recommendations=10):\n",
    "    \"\"\"\n",
    "    \\ Description:\n",
    "        - gets the index of the anime that matches the title;\n",
    "        - gets the pairwise similarity scores of all animes with the chosen anime;\n",
    "        - sort the animes based on the similarity socres on descending order;\n",
    "        - gets the scores of the top 'number_recommendations' animes, excluding the chosen one;\n",
    "        - gets the animes indices;\n",
    "        - returns the recommended animes id, title, synopsis, score, genre and image url.\n",
    "    \n",
    "    \\ Parameters:\n",
    "        - df: Pandas DataFrame;\n",
    "        - title: string;\n",
    "        - animes_indices: list of integers;\n",
    "        - cosine_similarity: NumPy array of floats;\n",
    "        - number_recommendation: integer.\n",
    "    \"\"\"\n",
    "    index = animes_indices[title]\n",
    "    \n",
    "    similarity_scores = list(enumerate(cosine_similarity[index]))\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda score: score[1], reverse=True)\n",
    "    similarity_scores = similarity_scores[1:number_recommendations+1]\n",
    "    \n",
    "    recommended_animes_indices = [index[0] for index in similarity_scores]\n",
    "    recommended_animes_scores = [index[1] for index in similarity_scores]\n",
    "    \n",
    "    recommendations_df = df.iloc[recommended_animes_indices][\n",
    "        ['id', 'title', 'synopsis', 'score', 'genres', 'image_url']\n",
    "    ].set_index('id')\n",
    "    recommendations_df['cosine_similarity'] = recommended_animes_scores\n",
    "    \n",
    "    return recommendations_df\n",
    "\n",
    "# ---- Functions: Collaborative Filtering ----\n",
    "def calculate_score(user_id, anime_id):\n",
    "    \"\"\"\n",
    "    \\ Description:\n",
    "        - drops the selected user from 'user_id' parameter on similarities and ratings matrices;\n",
    "        - calculates the total score and weight between the users;\n",
    "        - calculates the average user rating for the item from 'anime_id';\n",
    "        - returns the predicted rating balanced by the weight.\n",
    "    \n",
    "    \\ Parameters:\n",
    "        - user_id: integer;\n",
    "        - anime_id: integer.\n",
    "        \n",
    "    \\ Return:\n",
    "        - Baseline Prediction: float (when item is not into training dataset OR\n",
    "    none of the similar users have rated items in common with the 'user_id' parameter);\n",
    "        - Predicted Rating: float.\n",
    "    \"\"\"\n",
    "    # If the item is not into the training dataset, the baseline value is returned\n",
    "    if anime_id not in ratings_matrix.columns: return BASELINE_PREDICTION\n",
    "\n",
    "    # Dropping the selected user from 'user_id' parameter\n",
    "    similarity_scores = similarity_matrix[user_id].drop(labels=user_id)\n",
    "    normalized_ratings = normalized_ratings_matrix[anime_id].drop(index=user_id)\n",
    "    \n",
    "    # Dropping users that haven't rated the item\n",
    "    similarity_scores.drop(index=normalized_ratings[normalized_ratings.isnull()].index, inplace=True)\n",
    "    normalized_ratings.dropna(inplace=True)\n",
    "    \n",
    "    # If none of the other users have rated items in common with the user in question, the baseline value is returned\n",
    "    if similarity_scores.isna().all(): return BASELINE_PREDICTION\n",
    "    \n",
    "    # Calculating Predicted Rating\n",
    "    total_score = 0\n",
    "    total_weight = 0\n",
    "    \n",
    "    for user_id_rating in normalized_ratings.index:\n",
    "        # It is possible that another user rated the item but that\n",
    "        # they have not rated any items in common with the user in question\n",
    "        if not pd.isna(similarity_scores[user_id_rating]):\n",
    "            total_score += normalized_ratings[user_id_rating] * similarity_scores[user_id_rating]\n",
    "            total_weight += abs(similarity_scores[user_id_rating])\n",
    "            \n",
    "    avg_user_rating = ratings_matrix.T.mean()[user_id]\n",
    "    return avg_user_rating + total_score / total_weight\n",
    "\n",
    "def get_recommendations_collaborative_filtering(df, animes_df, user_id, number_recommendations=10):\n",
    "    \"\"\"\n",
    "    \\ Description:\n",
    "        - filters the top 10 recommendations by 'predicted_rating';\n",
    "        - creates a dataframe containing info about the filtered animes;\n",
    "        - merges 'predicted_rating' to the dataset;\n",
    "        - drops unuseful columns;\n",
    "        - returns the recommendations descended sorted by 'predicted_rating'.\n",
    "    \n",
    "    \\ Parameters:\n",
    "        - df: Pandas DataFrame;\n",
    "        - animes_df: Pandas DataFrame;\n",
    "        - user_id: integer;\n",
    "        - number_recommendations: integer.\n",
    "        \n",
    "    \\ Return:\n",
    "        - recommendations_df: Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    filtered_animes = df.loc[df.user_id == user_id]            \\\n",
    "      .sort_values(by='predicted_rating', ascending=False)    \\\n",
    "      .head(number_recommendations)\n",
    "    \n",
    "    recommended_animes_ids = filtered_animes.anime_id.unique().tolist()\n",
    "    \n",
    "    recommendations_df = animes_df.loc[animes_df.id.isin(recommended_animes_ids)][\n",
    "        ['id', 'title', 'synopsis', 'score', 'genres', 'image_url']\n",
    "    ]\n",
    "    \n",
    "    recommendations_df = recommendations_df.merge(\n",
    "        filtered_animes\n",
    "        , left_on='id'\n",
    "        , right_on='anime_id'\n",
    "        , how='left'\n",
    "    )\n",
    "    \n",
    "    recommendations_df.drop(columns=['anime_id', 'user_id'], inplace=True)\n",
    "    \n",
    "    return recommendations_df.sort_values(by='predicted_rating', ascending=False)\n",
    "\n",
    "# ---- Functions: General ----\n",
    "def get_recommendations(\n",
    "    predicted_ratings_df\n",
    "    , animes_collaborative_filtering_df\n",
    "    , user_id\n",
    "    , animes_content_filtering_df\n",
    "\t, title\n",
    "    , animes_indices\n",
    "    , cosine_similarity\n",
    "    , animes_demographic_filtering_df\n",
    "    , number_recommendations=10\n",
    "):\n",
    "    \"\"\"\n",
    "    \\ Description:\n",
    "        - if the selected anime has more than the cut-off number of ratings, recommendations\n",
    "    are made applying Collaborative Filtering User-Based Algorithm;\n",
    "        - if the selected anime does not have more than the cut-off number of ratings, recommendations\n",
    "    are made applying Content-Based Item Metadatas Algorithm;\n",
    "        - if the anime does not exist in the dataset, recommendations are made applying Demographic\n",
    "    Filtering.\n",
    "    \n",
    "    \\ Parameters:\n",
    "        - predicted_ratings_df: Pandas DataFrame;\n",
    "        - animes_collaborative_filtering_df: Pandas DataFrame;\n",
    "        - user_id: integer;\n",
    "        \n",
    "        - animes_content_filtering_df: Pandas DataFrame;\n",
    "        - title: string;\n",
    "        - animes_indices: Pandas Series;\n",
    "        - cosine_similarity: NumPy Array;\n",
    "        \n",
    "        - animes_demographic_filtering_df: Pandas DataFrame;\n",
    "        \n",
    "        - number_recommendations: integer.\n",
    "    \n",
    "    \\ Return:\n",
    "        - recommendations_df: Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    if (animes_collaborative_filtering_df['title'] == title).any():\n",
    "        print('- Using Collaborative Filtering User-Based Algorithm!')\n",
    "        print('---\\n\\n')\n",
    "        return get_recommendations_collaborative_filtering(\n",
    "            predicted_ratings_df\n",
    "            , animes_collaborative_filtering_df\n",
    "            , user_id\n",
    "            , number_recommendations\n",
    "        )\n",
    "    elif (animes_content_filtering_df['title'] == title).any():\n",
    "        print('- Using Content-Based Item Metadatas Based Algorithm!')\n",
    "        print('---\\n\\n')\n",
    "        return get_recommendations_content_filtering(\n",
    "            animes_content_filtering_df\n",
    "            , title\n",
    "            , animes_indices\n",
    "            , cosine_similarity_metadatas\n",
    "            , number_recommendations\n",
    "        )\n",
    "    else:\n",
    "        print('Using Demographic Filtering Algorithm!')\n",
    "        print('---\\n\\n')\n",
    "        return animes_demographic_filtering_df.sort_values(by='score', ascending=False).head(number_recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8328780b-945f-4820-b1dc-eafeed676098",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**- Demographic Filtering Algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa4b4d6c-db70-4adb-97c7-e4bd3371af93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Reading Dataset ----\n",
    "animes_demographic_filtering_df = pd.read_csv(f'{DATASETS_PATH}/anime-transformed-dataset-2023.csv', index_col='id')\n",
    "animes_demographic_filtering_df = animes_demographic_filtering_df.loc[\n",
    "    animes_demographic_filtering_df.score > 0\n",
    "][['title', 'genres', 'score', 'scored_by', 'popularity', 'image_url']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2babc19-7fd7-4483-ab03-a1ed5d561203",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**- Content-Based Filtering Items' Metadatas Algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04af3a1a-8313-4af2-97e8-7824ba41aef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Reading Dataset ----\n",
    "animes_content_filtering_df = pd.read_csv(f'{DATASETS_PATH}/anime-transformed-dataset-2023.csv', index_col='id')[\n",
    "    ['title', 'synopsis', 'score', 'genres', 'type', 'source', 'image_url']\n",
    "]\n",
    "\n",
    "# ---- Generating Sequential Text for Metadatas ----\n",
    "metadata_features = ['genres', 'type', 'source']\n",
    "animes_content_filtering_df['metadatas'] = generate_metadatas_sequential_text(animes_content_filtering_df, metadata_features)\n",
    "animes_content_filtering_df.head()\n",
    "\n",
    "# ---- Lower Casing ----\n",
    "animes_content_filtering_df.metadatas = animes_content_filtering_df.metadatas.apply(lambda metadata: metadata.lower())\n",
    "\n",
    "# ---- Removing All Break Lines (\\n) and Special Characters (\\t \\r \\x0b \\x0c) ----\n",
    "animes_content_filtering_df.metadatas = animes_content_filtering_df.metadatas.apply(lambda metadata: ' '.join(metadata.split()))\n",
    "\n",
    "# ---- Calculating TF-IDF ----\n",
    "tfidf_vectorizer = TfidfVectorizer(analyzer='word', norm='l2', stop_words='english')\n",
    "tfidf_metadatas = tfidf_vectorizer.fit_transform(animes_content_filtering_df.metadatas)\n",
    "\n",
    "# ---- Calculating Cosine Similarity ----\n",
    "cosine_similarity_metadatas = linear_kernel(tfidf_metadatas, tfidf_metadatas)\n",
    "\n",
    "# ---- Reseting Animes DataFrame Index ----\n",
    "#\n",
    "# - in order to the index follow a sequence from 0 to 'n', being 'n'\n",
    "# the total number of animes.\n",
    "#\n",
    "animes_content_filtering_df.reset_index(inplace=True)\n",
    "\n",
    "# ---- Getting Animes ID-Title Pairs ----\n",
    "animes_indices = pd.Series(animes_content_filtering_df.index, index=animes_content_filtering_df.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecf37d1-7778-48b9-a187-ef8a70eb5633",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**- Collaborative Filtering Users-Based Algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4710d237-5c3c-4af5-a8cc-cc7fcf4dc9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Reading Animes Dataset ----\n",
    "animes_collaborative_filtering_df = pd.read_csv(f'{DATASETS_PATH}/anime-transformed-dataset-2023.csv')[\n",
    "    ['id', 'title', 'synopsis', 'score', 'genres', 'image_url', 'scored_by']\n",
    "]\n",
    "\n",
    "# ---- Filterig Animes with more than or equal to a cutoff of number of Users Ratings ----\n",
    "minimum_number_of_ratings = animes_collaborative_filtering_df.scored_by.quantile(q=ANIMES_SCORED_BY_CUTOFF, interpolation='linear')\n",
    "animes_collaborative_filtering_df = animes_collaborative_filtering_df.loc[animes_collaborative_filtering_df.scored_by >= minimum_number_of_ratings].copy()\n",
    "\n",
    "# ---- Reading Ratings Dataset ----\n",
    "ratings_df = pd.read_csv(f'{DATASETS_PATH}/users-scores-transformed-2023.csv')[\n",
    "    ['user_id', 'anime_id', 'rating']\n",
    "]\n",
    "\n",
    "# ---- Filterig Ratings by Filtered Animes ----\n",
    "filtered_animes_ids = animes_collaborative_filtering_df.id.to_list()\n",
    "ratings_df = ratings_df.loc[ratings_df.anime_id.isin(filtered_animes_ids)].copy()\n",
    "\n",
    "# ---- Filtering Ratings with users with more than or equal to 2000 Ratings ----\n",
    "users_ratings_count = ratings_df.user_id.value_counts()\n",
    "ratings_df = ratings_df.loc[\n",
    "    ratings_df.user_id.isin(users_ratings_count[users_ratings_count >= USERS_NUMBER_RATINGS_CUTOFF].index)\n",
    "].copy()\n",
    "\n",
    "# ---- Splitting Dataset into Train and Validation ----\n",
    "train_ratings_df, valid_ratings_df = train_test_split(\n",
    "    ratings_df\n",
    "    , train_size=0.80\n",
    "    , test_size=0.20\n",
    "    , random_state=SEED\n",
    ")\n",
    "\n",
    "# ---- Calculating Ratings Matrix ----\n",
    "#\n",
    "# - values: users ratings to animes;\n",
    "# - indexes: users ids;\n",
    "# - columns: animes ids;\n",
    "#\n",
    "ratings_matrix = pd.pivot_table(train_ratings_df, values='rating', index='user_id', columns='anime_id')\n",
    "normalized_ratings_matrix = ratings_matrix.subtract(ratings_matrix.mean(axis=1), axis=0)\n",
    "\n",
    "# ---- Calculating Users Similarity Matrix ----\n",
    "similarity_matrix = ratings_matrix.T.corr(method='pearson')\n",
    "\n",
    "# ---- Predictions Calculation ----\n",
    "valid_ratings = np.array(valid_ratings_df['rating'])\n",
    "users_ids_list = valid_ratings_df['user_id']\n",
    "animes_ids_list = valid_ratings_df['anime_id']\n",
    "predicted_ratings = np.array([calculate_score(user_id, anime_id) for (user_id, anime_id) in zip(users_ids_list, animes_ids_list)])\n",
    "\n",
    "# ---- Validation ----\n",
    "rmse = np.sqrt(mean_squared_error(valid_ratings, predicted_ratings))\n",
    "\n",
    "# --- Predicted Ratings Dataset ----\n",
    "predicted_ratings_df = pd.DataFrame(columns=['user_id', 'anime_id', 'predicted_rating'])\n",
    "predicted_ratings_df['user_id'] = users_ids_list\n",
    "predicted_ratings_df['anime_id'] = animes_ids_list\n",
    "predicted_ratings_df['predicted_rating'] = predicted_ratings\n",
    "predicted_ratings_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9ceb1e-0973-4004-8f2c-8a1a73491c5e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**- Recommendations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a61d0a94-7d13-418f-87a5-4b647aedd2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3961                      fullmetal alchemist brotherhood\n",
       "4578             fullmetal alchemist brotherhood specials\n",
       "5174     fullmetal alchemist brotherhood - 4-koma theater\n",
       "11624                        brotherhood final fantasy xv\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Content-Based Filtering: Search Function ----\n",
    "#\n",
    "# - search animes titles that contains a given string in order to use it\n",
    "# in the next cell to get recommendations.\n",
    "#\n",
    "animes_content_filtering_df.title.loc[animes_content_filtering_df.title.str.contains('brotherhood')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f375bca-0a4d-45a6-a241-f41c24bbb8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Using Collaborative Filtering User-Based Algorithm!\n",
      "---\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>score</th>\n",
       "      <th>genres</th>\n",
       "      <th>image_url</th>\n",
       "      <th>predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4181</td>\n",
       "      <td>clannad after story</td>\n",
       "      <td>clannad: after story, the sequel to the critic...</td>\n",
       "      <td>8.93</td>\n",
       "      <td>supernatural, romance, drama</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/1299/...</td>\n",
       "      <td>9.768797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1575</td>\n",
       "      <td>code geass hangyaku no lelouch</td>\n",
       "      <td>in the year 2010, the holy empire of britannia...</td>\n",
       "      <td>8.70</td>\n",
       "      <td>action, sci-fi, award winning, drama</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/1032/...</td>\n",
       "      <td>9.749660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001</td>\n",
       "      <td>tengen toppa gurren lagann</td>\n",
       "      <td>simon and kamina were born and raised in a dee...</td>\n",
       "      <td>8.63</td>\n",
       "      <td>adventure, action, sci-fi, award winning</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/4/512...</td>\n",
       "      <td>9.661821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9989</td>\n",
       "      <td>ano hi mita hana no namae wo bokutachi wa mada...</td>\n",
       "      <td>jinta yadomi is peacefully living as a recluse...</td>\n",
       "      <td>8.31</td>\n",
       "      <td>supernatural, drama</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/5/796...</td>\n",
       "      <td>9.632413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11741</td>\n",
       "      <td>fate zero 2nd season</td>\n",
       "      <td>as the fourth holy grail war rages on with no ...</td>\n",
       "      <td>8.55</td>\n",
       "      <td>action, fantasy, supernatural</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/1522/...</td>\n",
       "      <td>9.623956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36862</td>\n",
       "      <td>made in abyss movie 3 fukaki tamashii no reimei</td>\n",
       "      <td>after bonding over a tragic loss, the long-suf...</td>\n",
       "      <td>8.63</td>\n",
       "      <td>fantasy, drama, adventure, sci-fi, mystery</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/1502/...</td>\n",
       "      <td>9.594341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12355</td>\n",
       "      <td>ookami kodomo no ame to yuki</td>\n",
       "      <td>hana, a hard-working college student, falls in...</td>\n",
       "      <td>8.58</td>\n",
       "      <td>slice of life, fantasy, award winning</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/9/357...</td>\n",
       "      <td>9.556795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1535</td>\n",
       "      <td>death note</td>\n",
       "      <td>brutal murders, petty thefts, and senseless vi...</td>\n",
       "      <td>8.62</td>\n",
       "      <td>suspense, supernatural</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/9/945...</td>\n",
       "      <td>9.526311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36990</td>\n",
       "      <td>non non biyori movie vacation</td>\n",
       "      <td>with summer vacation coming to an end, the gir...</td>\n",
       "      <td>8.25</td>\n",
       "      <td>slice of life</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/1044/...</td>\n",
       "      <td>9.460765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>572</td>\n",
       "      <td>kaze no tani no nausica</td>\n",
       "      <td>a millennium has passed since the catastrophic...</td>\n",
       "      <td>8.36</td>\n",
       "      <td>adventure, fantasy, award winning</td>\n",
       "      <td>https://cdn.myanimelist.net/images/anime/10/75...</td>\n",
       "      <td>9.422699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "4   4181                                clannad after story   \n",
       "2   1575                     code geass hangyaku no lelouch   \n",
       "3   2001                         tengen toppa gurren lagann   \n",
       "5   9989  ano hi mita hana no namae wo bokutachi wa mada...   \n",
       "6  11741                               fate zero 2nd season   \n",
       "8  36862    made in abyss movie 3 fukaki tamashii no reimei   \n",
       "7  12355                       ookami kodomo no ame to yuki   \n",
       "1   1535                                         death note   \n",
       "9  36990                      non non biyori movie vacation   \n",
       "0    572                            kaze no tani no nausica   \n",
       "\n",
       "                                            synopsis  score  \\\n",
       "4  clannad: after story, the sequel to the critic...   8.93   \n",
       "2  in the year 2010, the holy empire of britannia...   8.70   \n",
       "3  simon and kamina were born and raised in a dee...   8.63   \n",
       "5  jinta yadomi is peacefully living as a recluse...   8.31   \n",
       "6  as the fourth holy grail war rages on with no ...   8.55   \n",
       "8  after bonding over a tragic loss, the long-suf...   8.63   \n",
       "7  hana, a hard-working college student, falls in...   8.58   \n",
       "1  brutal murders, petty thefts, and senseless vi...   8.62   \n",
       "9  with summer vacation coming to an end, the gir...   8.25   \n",
       "0  a millennium has passed since the catastrophic...   8.36   \n",
       "\n",
       "                                       genres  \\\n",
       "4                supernatural, romance, drama   \n",
       "2        action, sci-fi, award winning, drama   \n",
       "3    adventure, action, sci-fi, award winning   \n",
       "5                         supernatural, drama   \n",
       "6               action, fantasy, supernatural   \n",
       "8  fantasy, drama, adventure, sci-fi, mystery   \n",
       "7       slice of life, fantasy, award winning   \n",
       "1                      suspense, supernatural   \n",
       "9                               slice of life   \n",
       "0           adventure, fantasy, award winning   \n",
       "\n",
       "                                           image_url  predicted_rating  \n",
       "4  https://cdn.myanimelist.net/images/anime/1299/...          9.768797  \n",
       "2  https://cdn.myanimelist.net/images/anime/1032/...          9.749660  \n",
       "3  https://cdn.myanimelist.net/images/anime/4/512...          9.661821  \n",
       "5  https://cdn.myanimelist.net/images/anime/5/796...          9.632413  \n",
       "6  https://cdn.myanimelist.net/images/anime/1522/...          9.623956  \n",
       "8  https://cdn.myanimelist.net/images/anime/1502/...          9.594341  \n",
       "7  https://cdn.myanimelist.net/images/anime/9/357...          9.556795  \n",
       "1  https://cdn.myanimelist.net/images/anime/9/945...          9.526311  \n",
       "9  https://cdn.myanimelist.net/images/anime/1044/...          9.460765  \n",
       "0  https://cdn.myanimelist.net/images/anime/10/75...          9.422699  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Getting Recommendations ----\n",
    "get_recommendations(\n",
    "\tpredicted_ratings_df=predicted_ratings_df\n",
    "\t, animes_collaborative_filtering_df=animes_collaborative_filtering_df\n",
    "\t, user_id=609_917\n",
    "\t, animes_content_filtering_df=animes_content_filtering_df\n",
    "\t, title='fullmetal alchemist brotherhood'\n",
    "\t, animes_indices=animes_indices\n",
    "\t, cosine_similarity=cosine_similarity_metadatas\n",
    "    , animes_demographic_filtering_df=animes_demographic_filtering_df\n",
    "\t, number_recommendations=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7021889c-5a21-4458-b39c-a9333af0a918",
   "metadata": {},
   "source": [
    "<h1 id='3-benchmarking' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>üç° | Benchmarking</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33ee96a8-e30e-4a53-889b-21cc493ba198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Imports ----\n",
    "import numpy as np                                           # pip install numpy\n",
    "import pandas as pd                                          # pip install pandas\n",
    "import psutil as psutil                                      # pip install psutil\n",
    "import os                                                    # pip install os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # pip install sklearn\n",
    "from sklearn.metrics import mean_squared_error               # pip install sklearn\n",
    "from sklearn.metrics.pairwise import linear_kernel           # pip install sklearn\n",
    "from sklearn.model_selection import train_test_split         # pip install sklearn\n",
    "import threading                                             # pip install threading\n",
    "import time                                                  # pip install time\n",
    "\n",
    "\n",
    "# ---- Constants ----\n",
    "ANIMES_SCORED_BY_CUTOFF = (0.75)\n",
    "USERS_NUMBER_RATINGS_CUTOFF = (2_000)\n",
    "BASELINE_PREDICTION = (2.5)\n",
    "\n",
    "NUMBER_OF_RECOMMENDATIONS = (10)\n",
    "NUMBER_OF_ITERATIONS = (10)\n",
    "DATASETS_PATH = ('./datasets')\n",
    "SEED = (20240420) # April 20, 2024 (fourth Bitcoin Halving)\n",
    "\n",
    "# ---- Settings ----\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# ---- Functions: Content-Based Filtering ----\n",
    "def generate_metadatas_sequential_text(dataset, features):\n",
    "    \"\"\"\n",
    "    \\ Description:\n",
    "        - iters each dataset row and features parameter's elements;\n",
    "        - if the value at row[feature] position is different than a single hyphen:\n",
    "             - the value gets all spaces replaced by underscores;\n",
    "             - the value gets all commas-spaces replaced by space;\n",
    "             - sequential_text is incremented by the resultant value and by a space at the end;\n",
    "             - sequential_text is stripped and appended into sequential_text_list;\n",
    "             - at the end, sequential_text_list is returned.\n",
    "    \n",
    "    \\ Paramters:\n",
    "        - dataset: Pandas DataFrame;\n",
    "        - features: list of strings.\n",
    "    \"\"\"\n",
    "    sequential_text_list = []\n",
    "    \n",
    "    for index, row in dataset.iterrows():\n",
    "        current_sequential_text = ''\n",
    "        for feature in features:\n",
    "            if row[feature] != '-':\n",
    "                current_sequential_text += row[feature].replace(' ', '_').replace(',_', ' ')\n",
    "                current_sequential_text += ' '\n",
    "                     \n",
    "        sequential_text_list.append(current_sequential_text.strip())\n",
    "    \n",
    "    return sequential_text_list\n",
    "\n",
    "def get_recommendations_content_filtering(df, title, animes_indices, cosine_similarity, number_recommendations=10):\n",
    "    \"\"\"\n",
    "    \\ Description:\n",
    "        - gets the index of the anime that matches the title;\n",
    "        - gets the pairwise similarity scores of all animes with the chosen anime;\n",
    "        - sort the animes based on the similarity socres on descending order;\n",
    "        - gets the scores of the top 'number_recommendations' animes, excluding the chosen one;\n",
    "        - gets the animes indices;\n",
    "        - returns the recommended animes id, title, synopsis, score, genre and image url.\n",
    "    \n",
    "    \\ Parameters:\n",
    "        - df: Pandas DataFrame;\n",
    "        - title: string;\n",
    "        - animes_indices: list of integers;\n",
    "        - cosine_similarity: NumPy array of floats;\n",
    "        - number_recommendation: integer.\n",
    "    \"\"\"\n",
    "    index = animes_indices[title]\n",
    "    \n",
    "    similarity_scores = list(enumerate(cosine_similarity[index]))\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda score: score[1], reverse=True)\n",
    "    similarity_scores = similarity_scores[1:number_recommendations+1]\n",
    "    \n",
    "    recommended_animes_indices = [index[0] for index in similarity_scores]\n",
    "    recommended_animes_scores = [index[1] for index in similarity_scores]\n",
    "    \n",
    "    recommendations_df = df.iloc[recommended_animes_indices][\n",
    "        ['id', 'title', 'synopsis', 'score', 'genres', 'image_url']\n",
    "    ].set_index('id')\n",
    "    recommendations_df['cosine_similarity'] = recommended_animes_scores\n",
    "    \n",
    "    return recommendations_df\n",
    "\n",
    "# ---- Functions: Collaborative Filtering ----\n",
    "def calculate_score(user_id, anime_id, ratings_matrix, normalized_ratings_matrix, similarity_matrix):\n",
    "    \"\"\"\n",
    "    \\ Description:\n",
    "        - drops the selected user from 'user_id' parameter on similarities and ratings matrices;\n",
    "        - calculates the total score and weight between the users;\n",
    "        - calculates the average user rating for the item from 'anime_id';\n",
    "        - returns the predicted rating balanced by the weight.\n",
    "    \n",
    "    \\ Parameters:\n",
    "        - user_id: integer;\n",
    "        - anime_id: integer;\n",
    "        - ratings_matrix: Pandas DataFrame;\n",
    "        - normalized_ratings_matrix: Pandas DataFrame;\n",
    "        - similarity_matrix: Pandas DataFrame.\n",
    "        \n",
    "    \\ Return:\n",
    "        - Baseline Prediction: float (when item is not into training dataset OR\n",
    "    none of the similar users have rated items in common with the 'user_id' parameter);\n",
    "        - Predicted Rating: float.\n",
    "    \"\"\"\n",
    "    # If the item is not into the training dataset, the baseline value is returned\n",
    "    if anime_id not in ratings_matrix.columns: return BASELINE_PREDICTION\n",
    "\n",
    "    # Dropping the selected user from 'user_id' parameter\n",
    "    similarity_scores = similarity_matrix[user_id].drop(labels=user_id)\n",
    "    normalized_ratings = normalized_ratings_matrix[anime_id].drop(index=user_id)\n",
    "    \n",
    "    # Dropping users that haven't rated the item\n",
    "    similarity_scores.drop(index=normalized_ratings[normalized_ratings.isnull()].index, inplace=True)\n",
    "    normalized_ratings.dropna(inplace=True)\n",
    "    \n",
    "    # If none of the other users have rated items in common with the user in question, the baseline value is returned\n",
    "    if similarity_scores.isna().all(): return BASELINE_PREDICTION\n",
    "    \n",
    "    # Calculating Predicted Rating\n",
    "    total_score = 0\n",
    "    total_weight = 0\n",
    "    \n",
    "    for user_id_rating in normalized_ratings.index:\n",
    "        # It is possible that another user rated the item but that\n",
    "        # they have not rated any items in common with the user in question\n",
    "        if not pd.isna(similarity_scores[user_id_rating]):\n",
    "            total_score += normalized_ratings[user_id_rating] * similarity_scores[user_id_rating]\n",
    "            total_weight += abs(similarity_scores[user_id_rating])\n",
    "            \n",
    "    avg_user_rating = ratings_matrix.T.mean()[user_id]\n",
    "    return avg_user_rating + total_score / total_weight\n",
    "\n",
    "def get_recommendations_collaborative_filtering(df, animes_df, user_id, number_recommendations=10):\n",
    "    \"\"\"\n",
    "    \\ Description:\n",
    "        - filters the top 10 recommendations by 'predicted_rating';\n",
    "        - creates a dataframe containing info about the filtered animes;\n",
    "        - merges 'predicted_rating' to the dataset;\n",
    "        - drops unuseful columns;\n",
    "        - returns the recommendations descended sorted by 'predicted_rating'.\n",
    "    \n",
    "    \\ Parameters:\n",
    "        - df: Pandas DataFrame;\n",
    "        - animes_df: Pandas DataFrame;\n",
    "        - user_id: integer;\n",
    "        - number_recommendations: integer.\n",
    "        \n",
    "    \\ Return:\n",
    "        - recommendations_df: Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    filtered_animes = df.loc[df.user_id == user_id]            \\\n",
    "      .sort_values(by='predicted_rating', ascending=False)    \\\n",
    "      .head(number_recommendations)\n",
    "    \n",
    "    recommended_animes_ids = filtered_animes.anime_id.unique().tolist()\n",
    "    \n",
    "    recommendations_df = animes_df.loc[animes_df.id.isin(recommended_animes_ids)][\n",
    "        ['id', 'title', 'synopsis', 'score', 'genres', 'image_url']\n",
    "    ]\n",
    "    \n",
    "    recommendations_df = recommendations_df.merge(\n",
    "        filtered_animes\n",
    "        , left_on='id'\n",
    "        , right_on='anime_id'\n",
    "        , how='left'\n",
    "    )\n",
    "    \n",
    "    recommendations_df.drop(columns=['anime_id', 'user_id'], inplace=True)\n",
    "    \n",
    "    return recommendations_df.sort_values(by='predicted_rating', ascending=False)\n",
    "\n",
    "# ---- Functions: General ----\n",
    "def get_recommendations(\n",
    "    predicted_ratings_df\n",
    "    , animes_collaborative_filtering_df\n",
    "    , user_id\n",
    "    , animes_content_filtering_df\n",
    "    , title\n",
    "    , animes_indices\n",
    "    , cosine_similarity\n",
    "    , animes_demographic_filtering_df\n",
    "    , number_recommendations=10\n",
    "):\n",
    "    \"\"\"\n",
    "    \\ Description:\n",
    "        - if the selected anime has more than the cut-off number of ratings, recommendations\n",
    "    are made applying Collaborative Filtering User-Based Algorithm;\n",
    "        - if the selected anime does not have more than the cut-off number of ratings, recommendations\n",
    "    are made applying Content-Based Item Metadatas Algorithm;\n",
    "        - if the anime does not exist in the dataset, recommendations are made applying Demographic\n",
    "    Filtering.\n",
    "    \n",
    "    \\ Parameters:\n",
    "        - predicted_ratings_df: Pandas DataFrame;\n",
    "        - animes_collaborative_filtering_df: Pandas DataFrame;\n",
    "        - user_id: integer;\n",
    "        \n",
    "        - animes_content_filtering_df: Pandas DataFrame;\n",
    "        - title: string;\n",
    "        - animes_indices: Pandas Series;\n",
    "        - cosine_similarity: NumPy Array;\n",
    "        \n",
    "        - animes_demographic_filtering_df: Pandas DataFrame;\n",
    "        \n",
    "        - number_recommendations: integer.\n",
    "    \n",
    "    \\ Return:\n",
    "        - recommendations_df: Pandas DataFrame.\n",
    "    \"\"\"\n",
    "    if (animes_collaborative_filtering_df['title'] == title).any():\n",
    "        return get_recommendations_collaborative_filtering(\n",
    "            predicted_ratings_df\n",
    "            , animes_collaborative_filtering_df\n",
    "            , user_id\n",
    "            , number_recommendations\n",
    "        )\n",
    "    elif (animes_content_filtering_df['title'] == title).any():\n",
    "        return get_recommendations_content_filtering(\n",
    "            animes_content_filtering_df\n",
    "            , title\n",
    "            , animes_indices\n",
    "            , cosine_similarity_metadatas\n",
    "            , number_recommendations\n",
    "        )\n",
    "    else:\n",
    "        return animes_demographic_filtering_df.sort_values(by='score', ascending=False).head(number_recommendations)\n",
    "    \n",
    "def hybrid_filtering(\n",
    "    demographic_filtering_df\n",
    "    , content_based_filtering_df\n",
    "    , collaborative_filtering_df\n",
    "    , ratings_df\n",
    "    , number_recommendations\n",
    "    , anime_title\n",
    "):\n",
    "    \"\"\"\n",
    "    \\ Description:\n",
    "        - applies Hybrid Filtering for Benchmark.\n",
    "        \n",
    "    \\ Paramters:\n",
    "        - demographic_filtering_df: Pandas DataFrame;\n",
    "        - content_based_filtering_df: Pandas DataFrame;\n",
    "        - collaborative_filtering_df: Pandas DataFrame;\n",
    "        - ratings_df: Pandas DataFrame;\n",
    "        - number_recommendations: integer.\n",
    "    \"\"\"\n",
    "    temp_demographic_filtering_df = demographic_filtering_df.copy()\n",
    "    temp_content_based_filtering_df = content_based_filtering_df.copy()\n",
    "    temp_collaborative_filtering_df = collaborative_filtering_df.copy()\n",
    "    temp_ratings_df = ratings_df.copy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ***************************************\n",
    "    # ** Content-Based Filtering Metadatas **\n",
    "    # ***************************************\n",
    "    \n",
    "    # ---- Calculating TF-IDF ----\n",
    "    tfidf_vectorizer = TfidfVectorizer(analyzer='word', norm='l2', stop_words='english')\n",
    "    tfidf_metadatas = tfidf_vectorizer.fit_transform(temp_content_based_filtering_df.metadatas)\n",
    "    \n",
    "    # ---- Calculating Cosine Similarity ----\n",
    "    cosine_similarity_metadatas = linear_kernel(tfidf_metadatas, tfidf_metadatas)\n",
    "    \n",
    "    # ---- Reseting Animes DataFrame Index ----\n",
    "    #\n",
    "    # - in order to the index follow a sequence from 0 to 'n', being 'n'\n",
    "    # the total number of animes.\n",
    "    #\n",
    "    temp_content_based_filtering_df.reset_index(inplace=True)\n",
    "    \n",
    "    # ---- Getting Animes ID-Title Pairs ----\n",
    "    temp_animes_indices = pd.Series(temp_content_based_filtering_df.index, index=temp_content_based_filtering_df.title)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ****************************************\n",
    "    # ** Collaborative Filtering User-Based **\n",
    "    # ****************************************\n",
    "    \n",
    "    # ---- Splitting Dataset into Train and Validation ----\n",
    "    train_ratings_df, valid_ratings_df = train_test_split(\n",
    "        temp_ratings_df\n",
    "        , train_size=0.80\n",
    "        , test_size=0.20\n",
    "        , random_state=SEED\n",
    "    )\n",
    "    \n",
    "    # ---- Calculating Ratings Matrix ----\n",
    "    #\n",
    "    # - values: users ratings to animes;\n",
    "    # - indexes: users ids;\n",
    "    # - columns: animes ids;\n",
    "    #\n",
    "    ratings_matrix = pd.pivot_table(train_ratings_df, values='rating', index='user_id', columns='anime_id')\n",
    "    normalized_ratings_matrix = ratings_matrix.subtract(ratings_matrix.mean(axis=1), axis=0)\n",
    "    \n",
    "    # ---- Calculating Users Similarity Matrix ----\n",
    "    similarity_matrix = ratings_matrix.T.corr(method='pearson')\n",
    "    \n",
    "    # ---- Predictions Calculation ----\n",
    "    valid_ratings = np.array(valid_ratings_df['rating'])\n",
    "    users_ids_list = valid_ratings_df['user_id']\n",
    "    animes_ids_list = valid_ratings_df['anime_id']\n",
    "    predicted_ratings = np.array([\n",
    "        calculate_score(user_id, anime_id, ratings_matrix, normalized_ratings_matrix, similarity_matrix)\n",
    "        for (user_id, anime_id)\n",
    "        in zip(users_ids_list, animes_ids_list)\n",
    "    ])\n",
    "    \n",
    "    # ---- Validation ----\n",
    "    rmse = np.sqrt(mean_squared_error(valid_ratings, predicted_ratings))\n",
    "    \n",
    "    # --- Predicted Ratings Dataset ----\n",
    "    predicted_ratings_df = pd.DataFrame(columns=['user_id', 'anime_id', 'predicted_rating'])\n",
    "    predicted_ratings_df['user_id'] = users_ids_list\n",
    "    predicted_ratings_df['anime_id'] = animes_ids_list\n",
    "    predicted_ratings_df['predicted_rating'] = predicted_ratings\n",
    "    predicted_ratings_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # *********************\n",
    "    # ** Recommendations **\n",
    "    # *********************\n",
    "    \n",
    "    # ---- Getting Recommendations ----\n",
    "    get_recommendations(\n",
    "      predicted_ratings_df=predicted_ratings_df\n",
    "      , animes_collaborative_filtering_df=temp_collaborative_filtering_df\n",
    "      , user_id=609_917\n",
    "      , animes_content_filtering_df=temp_content_based_filtering_df\n",
    "      , title=anime_title\n",
    "      , animes_indices=temp_animes_indices\n",
    "      , cosine_similarity=cosine_similarity_metadatas\n",
    "      , animes_demographic_filtering_df=temp_demographic_filtering_df\n",
    "      , number_recommendations=number_recommendations\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b289f31-da79-43cf-89c0-f69e3a652de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************************\n",
    "# ** Demographic Filtering **\n",
    "# ***************************\n",
    "\n",
    "# ---- Reading Dataset ----\n",
    "animes_demographic_filtering_df = pd.read_csv(f'{DATASETS_PATH}/anime-transformed-dataset-2023.csv', index_col='id')\n",
    "animes_demographic_filtering_df = animes_demographic_filtering_df.loc[\n",
    "    animes_demographic_filtering_df.score > 0\n",
    "][['title', 'genres', 'score', 'scored_by', 'popularity', 'image_url']]\n",
    "\n",
    "\n",
    "\n",
    "# ***************************************\n",
    "# ** Content-Based Filtering Metadatas **\n",
    "# ***************************************\n",
    "\n",
    "# ---- Reading Dataset ----\n",
    "animes_content_filtering_df = pd.read_csv(f'{DATASETS_PATH}/anime-transformed-dataset-2023.csv', index_col='id')[\n",
    "    ['title', 'synopsis', 'score', 'genres', 'type', 'source', 'image_url']\n",
    "]\n",
    "\n",
    "# ---- Generating Sequential Text for Metadatas ----\n",
    "metadata_features = ['genres', 'type', 'source']\n",
    "animes_content_filtering_df['metadatas'] = generate_metadatas_sequential_text(animes_content_filtering_df, metadata_features)\n",
    "\n",
    "# ---- Lower Casing ----\n",
    "animes_content_filtering_df.metadatas = animes_content_filtering_df.metadatas.apply(lambda metadata: metadata.lower())\n",
    "\n",
    "# ---- Removing All Break Lines (\\n) and Special Characters (\\t \\r \\x0b \\x0c) ----\n",
    "animes_content_filtering_df.metadatas = animes_content_filtering_df.metadatas.apply(lambda metadata: ' '.join(metadata.split()))\n",
    "\n",
    "\n",
    "\n",
    "# ****************************************\n",
    "# ** Collaborative Filtering User-Based **\n",
    "# ****************************************\n",
    "\n",
    "# ---- Reading Animes Dataset ----\n",
    "animes_collaborative_filtering_df = pd.read_csv(f'{DATASETS_PATH}/anime-transformed-dataset-2023.csv')[\n",
    "    ['id', 'title', 'synopsis', 'score', 'genres', 'image_url', 'scored_by']\n",
    "]\n",
    "\n",
    "# ---- Filterig Animes with more than or equal to a cutoff of number of Users Ratings ----\n",
    "minimum_number_of_ratings = animes_collaborative_filtering_df.scored_by.quantile(q=ANIMES_SCORED_BY_CUTOFF, interpolation='linear')\n",
    "animes_collaborative_filtering_df = animes_collaborative_filtering_df.loc[animes_collaborative_filtering_df.scored_by >= minimum_number_of_ratings].copy()\n",
    "\n",
    "# ---- Reading Ratings Dataset ----\n",
    "ratings_df = pd.read_csv(f'{DATASETS_PATH}/users-scores-transformed-2023.csv')[\n",
    "    ['user_id', 'anime_id', 'rating']\n",
    "]\n",
    "\n",
    "# ---- Filterig Ratings by Filtered Animes ----\n",
    "filtered_animes_ids = animes_collaborative_filtering_df.id.to_list()\n",
    "ratings_df = ratings_df.loc[ratings_df.anime_id.isin(filtered_animes_ids)].copy()\n",
    "\n",
    "# ---- Filtering Ratings with users with more than or equal to 2000 Ratings ----\n",
    "users_ratings_count = ratings_df.user_id.value_counts()\n",
    "ratings_df = ratings_df.loc[\n",
    "    ratings_df.user_id.isin(users_ratings_count[users_ratings_count >= USERS_NUMBER_RATINGS_CUTOFF].index)\n",
    "].copy()\n",
    "\n",
    "\n",
    "\n",
    "# ***************\n",
    "# ** Benchmark **\n",
    "# ***************\n",
    "\n",
    "# ---- Benchmark Dataset ----\n",
    "benchmark_df = pd.DataFrame(\n",
    "    columns=[\n",
    "        'iteration', 'algorithm', 'execution_time', 'avg_cpu_usage'\n",
    "        , 'min_cpu_usage', 'max_cpu_usage', 'avg_ram_usage'\n",
    "        , 'min_ram_usage', 'max_ram_usage'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab53c858-f2d9-4188-b1fa-d37ac3986742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Thread ----\n",
    "global python_process\n",
    "\n",
    "global iteration_cpu_usage\n",
    "global cpu_usage\n",
    "global min_cpu_usage\n",
    "global max_cpu_usage\n",
    "\n",
    "global iteration_ram_usage\n",
    "global ram_usage\n",
    "global min_ram_usage\n",
    "global max_ram_usage\n",
    "\n",
    "global execution_time\n",
    "\n",
    "global running\n",
    "\n",
    "def benchmark():\n",
    "    global iteration_cpu_usage\n",
    "    global iteration_ram_usage\n",
    "    global running\n",
    "    \n",
    "    running = True\n",
    "    \n",
    "    while running:\n",
    "        iteration_cpu_usage.append(python_process.cpu_percent(interval=0.1) / psutil.cpu_count())\n",
    "        iteration_ram_usage.append(python_process.memory_percent(memtype='uss'))\n",
    "        #iteration_ram_usage.append(python_process.memory_full_info().uss / 1024 / 1024) # in MB\n",
    "\n",
    "def start_thread():\n",
    "    global thread\n",
    "    thread = threading.Thread(target=benchmark)\n",
    "    thread.start()\n",
    "\n",
    "def stop_thread():\n",
    "    global thread\n",
    "    global running\n",
    "    \n",
    "    running = False\n",
    "    thread.join() # wait for thread's end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7dd94fa-4457-4087-aa28-57792b2ba158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Calculations of iteration 0\n",
      "- Calculations of iteration 1\n",
      "- Calculations of iteration 2\n",
      "- Calculations of iteration 3\n",
      "- Calculations of iteration 4\n",
      "- Calculations of iteration 5\n",
      "- Calculations of iteration 6\n",
      "- Calculations of iteration 7\n",
      "- Calculations of iteration 8\n",
      "- Calculations of iteration 9\n"
     ]
    }
   ],
   "source": [
    "# ---- Benchmark ----\n",
    "python_process = psutil.Process(os.getpid())\n",
    "\n",
    "iteration_cpu_usage = []\n",
    "cpu_usage = []\n",
    "min_cpu_usage = []\n",
    "max_cpu_usage = []\n",
    "\n",
    "iteration_ram_usage = []\n",
    "ram_usage = []\n",
    "min_ram_usage = []\n",
    "max_ram_usage = []\n",
    "\n",
    "execution_time = []\n",
    "\n",
    "running = False\n",
    "\n",
    "animes_title = [\n",
    "    'fullmetal alchemist brotherhood', 'fullmetal alchemist brotherhood', 'fullmetal alchemist brotherhood', 'fullmetal alchemist brotherhood'\n",
    "    , '?', '?', '?'\n",
    "    , '?', '?', '?'\n",
    "]\n",
    "\n",
    "for iteration in range(NUMBER_OF_ITERATIONS):\n",
    "    # ---- Globals ----\n",
    "    global iteration_cpu_usage\n",
    "    global cpu_usage\n",
    "    global min_cpu_usage\n",
    "    global max_cpu_usage\n",
    "    \n",
    "    global iteration_ram_usage\n",
    "    global ram_usage\n",
    "    global min_ram_usage\n",
    "    global max_ram_usage\n",
    "    \n",
    "    global execution_time\n",
    "    \n",
    "    # ---- Thread ----\n",
    "    iteration_cpu_usage = []\n",
    "    iteration_ram_usage = []\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    start_thread()\n",
    "    \n",
    "    try:\n",
    "        hybrid_filtering(\n",
    "            animes_demographic_filtering_df\n",
    "            , animes_content_filtering_df\n",
    "            , animes_collaborative_filtering_df\n",
    "            , ratings_df\n",
    "            , NUMBER_OF_RECOMMENDATIONS\n",
    "            , animes_title[iteration]\n",
    "        )\n",
    "    except Exception as exception: print(f'- An exception occurred: {exception}')\n",
    "    finally: stop_thread()\n",
    "    \n",
    "    # ---- Computing Bechmarks ----\n",
    "    print(f'- Calculations of iteration {iteration}')\n",
    "    \n",
    "    final_time = time.perf_counter()\n",
    "    execution_time.append(final_time - start_time)\n",
    "    \n",
    "    cpu_usage.append(sum(iteration_cpu_usage) / len(iteration_cpu_usage))\n",
    "    min_cpu_usage.append(min(iteration_cpu_usage))\n",
    "    max_cpu_usage.append(max(iteration_cpu_usage))\n",
    "    \n",
    "    ram_usage.append(sum(iteration_ram_usage) / len(iteration_ram_usage))\n",
    "    min_ram_usage.append(min(iteration_ram_usage))\n",
    "    max_ram_usage.append(max(iteration_ram_usage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0226a6a-6d04-422b-a3cb-e892014c565e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>avg_cpu_usage</th>\n",
       "      <th>min_cpu_usage</th>\n",
       "      <th>max_cpu_usage</th>\n",
       "      <th>avg_ram_usage</th>\n",
       "      <th>min_ram_usage</th>\n",
       "      <th>max_ram_usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Hybrid Filtering</td>\n",
       "      <td>232.815563</td>\n",
       "      <td>11.763836</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.6250</td>\n",
       "      <td>22.977762</td>\n",
       "      <td>1.172168</td>\n",
       "      <td>44.168416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Hybrid Filtering</td>\n",
       "      <td>250.184384</td>\n",
       "      <td>11.688466</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1250</td>\n",
       "      <td>26.164434</td>\n",
       "      <td>1.158836</td>\n",
       "      <td>46.662203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hybrid Filtering</td>\n",
       "      <td>195.960814</td>\n",
       "      <td>11.926131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.3375</td>\n",
       "      <td>26.070355</td>\n",
       "      <td>1.160801</td>\n",
       "      <td>49.996925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Hybrid Filtering</td>\n",
       "      <td>194.296961</td>\n",
       "      <td>12.172251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.6000</td>\n",
       "      <td>35.412753</td>\n",
       "      <td>1.158965</td>\n",
       "      <td>58.004571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Hybrid Filtering</td>\n",
       "      <td>182.308860</td>\n",
       "      <td>12.303803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1250</td>\n",
       "      <td>35.415534</td>\n",
       "      <td>1.165212</td>\n",
       "      <td>62.632606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Hybrid Filtering</td>\n",
       "      <td>163.964925</td>\n",
       "      <td>12.231969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.3375</td>\n",
       "      <td>25.645048</td>\n",
       "      <td>1.161380</td>\n",
       "      <td>58.433024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Hybrid Filtering</td>\n",
       "      <td>182.320029</td>\n",
       "      <td>12.305696</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.6000</td>\n",
       "      <td>35.507852</td>\n",
       "      <td>1.162378</td>\n",
       "      <td>62.631382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Hybrid Filtering</td>\n",
       "      <td>171.493498</td>\n",
       "      <td>12.092040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.1250</td>\n",
       "      <td>26.301949</td>\n",
       "      <td>1.172909</td>\n",
       "      <td>59.183823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Hybrid Filtering</td>\n",
       "      <td>170.785071</td>\n",
       "      <td>12.257074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.6000</td>\n",
       "      <td>28.401564</td>\n",
       "      <td>1.167080</td>\n",
       "      <td>59.017788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Hybrid Filtering</td>\n",
       "      <td>171.382266</td>\n",
       "      <td>12.177311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.6000</td>\n",
       "      <td>22.924738</td>\n",
       "      <td>1.161831</td>\n",
       "      <td>57.461896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iteration         algorithm  execution_time  avg_cpu_usage  min_cpu_usage  \\\n",
       "0          0  Hybrid Filtering      232.815563      11.763836            0.0   \n",
       "1          1  Hybrid Filtering      250.184384      11.688466            0.0   \n",
       "2          2  Hybrid Filtering      195.960814      11.926131            0.0   \n",
       "3          3  Hybrid Filtering      194.296961      12.172251            0.0   \n",
       "4          4  Hybrid Filtering      182.308860      12.303803            0.0   \n",
       "5          5  Hybrid Filtering      163.964925      12.231969            0.0   \n",
       "6          6  Hybrid Filtering      182.320029      12.305696            0.0   \n",
       "7          7  Hybrid Filtering      171.493498      12.092040            0.0   \n",
       "8          8  Hybrid Filtering      170.785071      12.257074            0.0   \n",
       "9          9  Hybrid Filtering      171.382266      12.177311            0.0   \n",
       "\n",
       "   max_cpu_usage  avg_ram_usage  min_ram_usage  max_ram_usage  \n",
       "0        16.6250      22.977762       1.172168      44.168416  \n",
       "1        16.1250      26.164434       1.158836      46.662203  \n",
       "2        14.3375      26.070355       1.160801      49.996925  \n",
       "3        12.6000      35.412753       1.158965      58.004571  \n",
       "4        16.1250      35.415534       1.165212      62.632606  \n",
       "5        14.3375      25.645048       1.161380      58.433024  \n",
       "6        12.6000      35.507852       1.162378      62.631382  \n",
       "7        16.1250      26.301949       1.172909      59.183823  \n",
       "8        12.6000      28.401564       1.167080      59.017788  \n",
       "9        12.6000      22.924738       1.161831      57.461896  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Storaging Data ----\n",
    "benchmark_df['iteration'] = [number for number in range(NUMBER_OF_ITERATIONS)]\n",
    "benchmark_df['algorithm'] = 'Hybrid Filtering'\n",
    "benchmark_df['execution_time'] = execution_time\n",
    "\n",
    "benchmark_df['avg_cpu_usage'] = cpu_usage\n",
    "benchmark_df['min_cpu_usage'] = min_cpu_usage\n",
    "benchmark_df['max_cpu_usage'] = max_cpu_usage\n",
    "\n",
    "benchmark_df['avg_ram_usage'] = ram_usage\n",
    "benchmark_df['min_ram_usage'] = min_ram_usage\n",
    "benchmark_df['max_ram_usage'] = max_ram_usage\n",
    "\n",
    "benchmark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acd7292b-52cd-4d8c-954b-5d7728e12aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Exporting Data ----\n",
    "benchmark_df.to_csv(\n",
    "    f'{DATASETS_PATH}/benchmarks/hybrid-filtering.csv'\n",
    "    , index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf75d464-ff88-4413-bed0-12ae10f3b2c1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h1 id='reach-me' style='color:#7159c1; border-bottom:3px solid #7159c1; letter-spacing:2px; font-family:JetBrains Mono; font-weight: bold; text-align:left; font-size:240%;padding:0'>üì´ | Reach Me</h1>\n",
    "\n",
    "> **Email** - [csfelix08@gmail.com](mailto:csfelix08@gmail.com?)\n",
    "\n",
    "> **Linkedin** - [linkedin.com/in/csfelix/](https://www.linkedin.com/in/csfelix/)\n",
    "\n",
    "> **GitHub:** - [CSFelix](https://github.com/CSFelix)\n",
    "\n",
    "> **Kaggle** - [DSFelix](https://www.kaggle.com/dsfelix)\n",
    "\n",
    "> **Portfolio** - [CSFelix.io](https://csfelix.github.io/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
